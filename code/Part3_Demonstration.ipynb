{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5cbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d99fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"myapp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3051c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/apache-spark/3.2.1/libexec\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SPARK_HOME'])\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f757a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Method to create classification Report\n",
    "def makeClassificationReport(metricsArray):\n",
    "    TN = metricsArray[0][0]\n",
    "    FN = metricsArray[1][0]\n",
    "    FP = metricsArray[0][1]\n",
    "    TP = metricsArray[1][1]\n",
    "    Accuracy = (TP+TN)/(TP+FN+TN+FP)\n",
    "    Precision = TP/(TP+FP)\n",
    "    Recall = TP / (TP + FN)\n",
    "    F1Score = 2*(Precision * Recall)/(Precision + Recall)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"Precision: \",Precision)\n",
    "    print(\"Recall: \",Recall)\n",
    "    print(\"F1- Score: \", F1Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395ee1c",
   "metadata": {},
   "source": [
    "## 1. READING DEMONSTRATION DATA \n",
    "- We are reading the cleaned dataset set prepared in previous Juypter Notebook\n",
    "- Data is stored on S3 in following location:  s3://brfss-big-data-project/HeartRiskData/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605d08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ LOCAL DATA FILE\n",
    "# Comment if reading from S3\n",
    "\n",
    "# heartData = spark.read.csv(\"../../../BRFSS/HeartRiskData/\", header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b04faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/02 18:55:57 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# READ FROM S3 BUCKET\n",
    "#Comment if reading locally\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\")\n",
    "\n",
    "heartData = spark.read.csv(\"s3a://brfss-big-data-project/HeartRiskData/\", header = 'true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff9b4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/02 18:56:14 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 2:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstration Dataset Count: 52052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numericCols = ['BMI','HighChol','CholCheck','FruitConsume','VegetableConsume','Smoker','HeavyDrinker', \\\n",
    "               'Diabetes','Stroke','Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth', \\\n",
    "               'PhysicalHealth','MentalHealth','DifficultyWalking','Gender','Age','Education','Income']\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "df = assembler.transform(heartData)\n",
    "\n",
    "# We are using the 10% data that was previously reserved (same seed)\n",
    "modelData, demoData = df.randomSplit([0.9, 0.1], seed = 2018)\n",
    "print(\"Demonstration Dataset Count: \" + str(demoData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae570882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+--------------------+\n",
      "|HeartDisease|State|  BMI|HighBP|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender|Age|Education|Income|            features|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+--------------------+\n",
      "|         0.0| 22.0|23.91|   0.0|     0.0|      1.0|         1.0|             1.0|   1.0|         0.0|     0.0|   0.0|       0.0|              0.0|             1.0|          5.0|           0.0|         2.0|              0.0|   0.0|4.0|      4.0|   5.0|(20,[0,2,3,4,5,11...|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd5c804f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HeartDisease: double (nullable = true)\n",
      " |-- State: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- FruitConsume: double (nullable = true)\n",
      " |-- VegetableConsume: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- HeavyDrinker: double (nullable = true)\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- Healthcare: double (nullable = true)\n",
      " |-- NoDoctorDueToCost: double (nullable = true)\n",
      " |-- PhysicalActivity: double (nullable = true)\n",
      " |-- GeneralHealth: double (nullable = true)\n",
      " |-- PhysicalHealth: double (nullable = true)\n",
      " |-- MentalHealth: double (nullable = true)\n",
      " |-- DifficultyWalking: double (nullable = true)\n",
      " |-- Gender: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Education: double (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3fedc",
   "metadata": {},
   "source": [
    "## 3. READING SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2983fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099b191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ LOCAL MODEL\n",
    "# Comment if Reading from S3\n",
    "# mPath = \"../model/\"\n",
    "# persistedModel = RandomForestClassificationModel.load(mPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e75a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# READ MODEL FROM S3\n",
    "# Comment if reading locally stored model\n",
    "mPath = \"s3a://brfss-big-data-project/model/\"\n",
    "persistedModel = RandomForestClassificationModel.load(mPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d252bc",
   "metadata": {},
   "source": [
    "##  4. MAKING PREDICTIONS ON UNSEEN DEMONSTRATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d01ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|HeartDisease|prediction|\n",
      "+------------+----------+\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       1.0|\n",
      "+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = persistedModel.transform(demoData)\n",
    "predictions.select(\"HeartDisease\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f24b3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7861604556281628\n",
      "Test Error = 0.21383954437183716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:==================================================>       (7 + 1) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7465c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusuion Matrix:\n",
      "[[34303. 12882.]\n",
      " [ 1076.  3791.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','HeartDisease']).withColumn('HeartDisease', F.col('HeartDisease').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','HeartDisease'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(\"Confusuion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b2de50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "Accuracy:  0.7318450779989242\n",
      "Precision:  0.22737359803274756\n",
      "Recall:  0.7789192521060201\n",
      "F1- Score:  0.35199628597957294\n"
     ]
    }
   ],
   "source": [
    "makeClassificationReport(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1647b7e",
   "metadata": {},
   "source": [
    "## 5. MAKING PREDICTIONS BASED ON AN INDIVIUAL's DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d96de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "numericCols = ['BMI','HighChol','CholCheck','FruitConsume','VegetableConsume','Smoker','HeavyDrinker', \\\n",
    "               'Diabetes','Stroke','Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth', \\\n",
    "               'PhysicalHealth','MentalHealth','DifficultyWalking','Gender','Age','Education','Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67ea60",
   "metadata": {},
   "source": [
    "#### 5.1 Predicting on person with poor health and habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9841cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "poorHealthPerson = [{ \"HeartDisease\" : -1, \"State\" : 22 , \"BMI\" : 35, \"HighBP\" : 1, \"HighChol\" : 1, \"CholCheck\" :1, \\\n",
    "             \"FruitConsume\" : 0, \"VegetableConsume\" : 0 , \"Smoker\" : 1 , \"HeavyDrinker\" : 1, \\\n",
    "                    \"Diabetes\" : 1 , \"Stroke\" : 1 , \"Healthcare\": 0 , \"NoDoctorDueToCost\" : 1, \\\n",
    "                    \"PhysicalActivity\" : 0 , \"GeneralHealth\": 1 ,\"PhysicalHealth\" : 20 , \"MentalHealth\" : 5 ,\\\n",
    "                    \"DifficultyWalking\" : 1 , \"Gender\" : 1 ,\"Age\" : 10 , \"Education\" : 2 , \"Income\": 1 }]\n",
    "             \n",
    "dfPoorHealth = spark.createDataFrame(poorHealthPerson)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "poorHealthSample= assembler.transform(dfPoorHealth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c79f6de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = persistedModel.transform(poorHealthSample)\n",
    "predictions.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748f1fd",
   "metadata": {},
   "source": [
    "#### 5.2 Predicting on person with good health and habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54f19e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodHealthPerson = [{ \"HeartDisease\" : -1, \"State\" : 22 , \"BMI\" : 20, \"HighBP\" : 0, \"HighChol\" : 0, \"CholCheck\" :0, \\\n",
    "             \"FruitConsume\" : 1, \"VegetableConsume\" : 1 , \"Smoker\" : 0 , \"HeavyDrinker\" : 0, \\\n",
    "                    \"Diabetes\" : 0 , \"Stroke\" : 1 , \"Healthcare\": 1 , \"NoDoctorDueToCost\" : 0, \\\n",
    "                    \"PhysicalActivity\" : 1 , \"GeneralHealth\": 4 ,\"PhysicalHealth\" : 3 , \"MentalHealth\" : 1 ,\\\n",
    "                    \"DifficultyWalking\" : 0 , \"Gender\" : 0 ,\"Age\" : 10 , \"Education\" : 2 , \"Income\": 1 }]\n",
    "             \n",
    "dfGoodHealth = spark.createDataFrame(goodHealthPerson)\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "goodHealthSample= assembler.transform(dfGoodHealth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b68fb693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = persistedModel.transform(goodHealthSample)\n",
    "predictions.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a79f40",
   "metadata": {},
   "source": [
    "#### 5.3 Enter your stats to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1517a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMI = 21\n",
    "HighBP = 0\n",
    "HighChol = 0\n",
    "CholCheck = 0\n",
    "FruitConsume = 0\n",
    "VegetableConsume = 1\n",
    "Smoker = 0\n",
    "HeavyDrinker = 0\n",
    "Diabetes = 0 \n",
    "Stroke = 0\n",
    "Healthcare = 1\n",
    "NoDoctorDueToCost = 0\n",
    "PhysicalActivity = 0\n",
    "GeneralHealth = 4\n",
    "PhysicalHealth = 2\n",
    "MentalHealth = 0\n",
    "DifficultyWalking = 0\n",
    "Gender = 0\n",
    "Age = 3\n",
    "Education = 4\n",
    "Education = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99108168",
   "metadata": {},
   "outputs": [],
   "source": [
    "yourData = [{ \"HeartDisease\" : -1, \"State\" : 22 , \"BMI\" : BMI, \"HighBP\" : HighBP, \"HighChol\" : HighChol, \"CholCheck\" :CholCheck, \\\n",
    "             \"FruitConsume\" : FruitConsume, \"VegetableConsume\" : VegetableConsume , \"Smoker\" : Smoker , \"HeavyDrinker\" : HeavyDrinker, \\\n",
    "                    \"Diabetes\" : Diabetes , \"Stroke\" : Stroke , \"Healthcare\": Healthcare , \"NoDoctorDueToCost\" : NoDoctorDueToCost, \\\n",
    "                    \"PhysicalActivity\" : PhysicalActivity , \"GeneralHealth\": GeneralHealth ,\"PhysicalHealth\" : PhysicalHealth , \"MentalHealth\" : MentalHealth ,\\\n",
    "                    \"DifficultyWalking\" : DifficultyWalking , \"Gender\" : Gender,\"Age\" : Age , \"Education\" : Education , \"Income\": Education }]\n",
    "             \n",
    "dfYourData = spark.createDataFrame(yourData)\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "yourSample= assembler.transform(dfYourData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6789ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction based on your data are as follows: \n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = persistedModel.transform(yourSample)\n",
    "print( \"Prediction based on your data are as follows: \")\n",
    "predictions.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbeadd",
   "metadata": {},
   "source": [
    "# ---- END ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a315c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
