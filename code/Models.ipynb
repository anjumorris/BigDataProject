{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f859455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d99fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"myapp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3051c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/apache-spark/3.2.1/libexec\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SPARK_HOME'])\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395ee1c",
   "metadata": {},
   "source": [
    "## 1. READING CLEANED DATA \n",
    "- We are reading the cleaned dataset set prepared in previous Juypter Notebook\n",
    "- Data is stored on S3 in following location:  s3://brfss-big-data-project/HeartRiskData/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605d08cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# READ LOCAL DATA FILE\n",
    "# Comment if reading from S3\n",
    "\n",
    "heartData = spark.read.csv(\"../../../BRFSS/HeartRiskData/\", header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b04faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FROM S3 BUCKET\n",
    "#Comment if reading locally\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "# sc._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\")\n",
    "\n",
    "# heartData = spark.read.csv(\"s3a://brfss-big-data-project/HeartRiskData/\", header = 'true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40da8a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HeartDisease: double (nullable = true)\n",
      " |-- State: double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- CholCheck: double (nullable = true)\n",
      " |-- FruitConsume: double (nullable = true)\n",
      " |-- VegetableConsume: double (nullable = true)\n",
      " |-- Smoker: double (nullable = true)\n",
      " |-- HeavyDrinker: double (nullable = true)\n",
      " |-- Diabetes: double (nullable = true)\n",
      " |-- Stroke: double (nullable = true)\n",
      " |-- Healthcare: double (nullable = true)\n",
      " |-- NoDoctorDueToCost: double (nullable = true)\n",
      " |-- PhysicalActivity: double (nullable = true)\n",
      " |-- GeneralHealth: double (nullable = true)\n",
      " |-- PhysicalHealth: double (nullable = true)\n",
      " |-- MentalHealth: double (nullable = true)\n",
      " |-- DifficultyWalking: double (nullable = true)\n",
      " |-- Gender: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Education: double (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9f3a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+\n",
      "|HeartDisease|State|  BMI|HighBP|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender|Age|Education|Income|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+\n",
      "|         0.0| 22.0|23.91|   0.0|     0.0|      1.0|         1.0|             1.0|   1.0|         0.0|     0.0|   0.0|       0.0|              0.0|             1.0|          5.0|           0.0|         2.0|              0.0|   0.0|4.0|      4.0|   5.0|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f1c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|HeartDisease|  BMI|\n",
      "+------------+-----+\n",
      "|         0.0|23.91|\n",
      "|         1.0|39.15|\n",
      "|         0.0|33.36|\n",
      "|         0.0|29.84|\n",
      "|         0.0|24.82|\n",
      "+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.select(['HeartDisease','BMI']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b777355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Data Frame:\n",
      "(519171, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of the Data Frame:\")\n",
    "print((heartData.count(), len(heartData.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24097a1",
   "metadata": {},
   "source": [
    "Note: We can see that after cleaning we have 0.5 million data points across 22 features with the target \"HeartDisease\" that indicates if the person is either suffering from heart disease or has had a heart attack. \n",
    "0 = No \n",
    "1 = Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ff5d0",
   "metadata": {},
   "source": [
    "## 2. EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4014653",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = heartData.groupBy('HeartDisease').count().collect()\n",
    "total_counts = heartData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb3274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage not having any heart issues\n",
      "90.79494039536107\n",
      "Percentage havingheart issues\n",
      "9.205059604638933\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage not having any heart issues\" )\n",
    "print(counts[0][1]/total_counts*100)\n",
    "print(\"Percentage havingheart issues\" )\n",
    "print(counts[1][1]/total_counts*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1842fd",
   "metadata": {},
   "source": [
    "Note: The data is imbalanced only 9.2% has heart issues ... so we may need to either oversample or undersample when training our models. Additionally we will have to consider measures other than just accuracy to judge our model performance. Precision, Recall and F1 score will have to be considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efba82",
   "metadata": {},
   "source": [
    "#### 2.1 Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9946acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|summary|              BMI|           HighChol|          CholCheck|       FruitConsume|   VegetableConsume|\n",
      "+-------+-----------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|  count|           519171|             519171|             519171|             519171|             519171|\n",
      "|   mean|28.56327531776717| 0.3915029922703695| 0.9600959991987226| 0.6461416373410688|  0.833698338312425|\n",
      "| stddev|6.330915524634669|0.48808693711025664|0.19573386348664162|0.47816635414421166|0.37235156245084894|\n",
      "|    min|             12.0|                0.0|                0.0|                0.0|                0.0|\n",
      "|    max|             98.7|                1.0|                1.0|                1.0|                1.0|\n",
      "+-------+-----------------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.describe(['BMI','HighChol','CholCheck','FruitConsume','VegetableConsume']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef47701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+-------------------+\n",
      "|summary|             Smoker|       HeavyDrinker|           Diabetes|             Stroke|\n",
      "+-------+-------------------+-------------------+-------------------+-------------------+\n",
      "|  count|             519171|             519171|             519171|             519171|\n",
      "|   mean|     0.431405066924|0.06193912988206198|0.17125571343545767|0.04223656560169963|\n",
      "| stddev|0.49527286179548236|0.24104519490348594|0.37673262060037704|0.20112860573716723|\n",
      "|    min|                0.0|                0.0|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.describe(['Smoker','HeavyDrinker','Diabetes','Stroke']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be747ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|         Healthcare|  NoDoctorDueToCost|  PhysicalActivity|     GeneralHealth|\n",
      "+-------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|             519171|             519171|            519171|            519171|\n",
      "|   mean| 0.9390759499278658|0.09431189338387545|0.7490788198878597|3.4484206552369066|\n",
      "| stddev|0.23919117959178865|0.29226242433231586|0.4335436581501136|1.0641187958099112|\n",
      "|    min|                0.0|                0.0|               0.0|               1.0|\n",
      "|    max|                1.0|                1.0|               1.0|               5.0|\n",
      "+-------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.describe(['Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ef8975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-------------------+\n",
      "|summary|   PhysicalHealth|      MentalHealth|  DifficultyWalking|\n",
      "+-------+-----------------+------------------+-------------------+\n",
      "|  count|           519171|            519171|             519171|\n",
      "|   mean|4.361489759636036|3.5516814305883804|0.16746120257102187|\n",
      "| stddev|8.792808096235884| 7.733453215085699|0.37338748873597627|\n",
      "|    min|              0.0|               0.0|                0.0|\n",
      "|    max|             30.0|              30.0|                1.0|\n",
      "+-------+-----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.describe(['PhysicalHealth','MentalHealth','DifficultyWalking']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a064987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------------------+-----------------+\n",
      "|summary|             Gender|               Age|         Education|           Income|\n",
      "+-------+-------------------+------------------+------------------+-----------------+\n",
      "|  count|             519171|            519171|            519171|           519171|\n",
      "|   mean|0.46337911786290065|7.9175435453829275| 5.063150676751976|6.083748899688157|\n",
      "| stddev| 0.4986575878758885| 3.241323105698738|0.9768962159188829|2.073786990025714|\n",
      "|    min|                0.0|               1.0|               1.0|              1.0|\n",
      "|    max|                1.0|              13.0|               6.0|              8.0|\n",
      "+-------+-------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heartData.describe(['Gender','Age','Education','Income']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e377cb",
   "metadata": {},
   "source": [
    "Notes: Most of the data is boolean or binned like for Age. The data is quite consistent . BMI max is at 98.7 which is  large but is a possible value so we will not remove such values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fcc6db",
   "metadata": {},
   "source": [
    "#### 2.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67bd3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ecc31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = heartData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f74484c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes a lot of time \n",
    "corrList = []\n",
    "for col in colNames:\n",
    "    pearsonCorr = heartData.corr('HeartDisease',col)\n",
    "    corrList.append((\"BMI - \"+col,pearsonCorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecc1df80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BMI - HeartDisease', 1.0),\n",
       " ('BMI - State', 0.006444321393978534),\n",
       " ('BMI - BMI', 0.05058519245234513),\n",
       " ('BMI - HighBP', 0.2098579059479823),\n",
       " ('BMI - HighChol', 0.1859344957309097),\n",
       " ('BMI - CholCheck', 0.04574915829500349),\n",
       " ('BMI - FruitConsume', -0.012932002071759112),\n",
       " ('BMI - VegetableConsume', -0.023949296306889675),\n",
       " ('BMI - Smoker', 0.11680965215675526),\n",
       " ('BMI - HeavyDrinker', -0.03037897687609935),\n",
       " ('BMI - Diabetes', 0.17086995852514197),\n",
       " ('BMI - Stroke', 0.1990394390425505),\n",
       " ('BMI - Healthcare', 0.027174079890363554),\n",
       " ('BMI - NoDoctorDueToCost', 0.026098505344340245),\n",
       " ('BMI - PhysicalActivity', -0.08797288374111345),\n",
       " ('BMI - GeneralHealth', -0.2507726735558453),\n",
       " ('BMI - PhysicalHealth', 0.18450992906634142),\n",
       " ('BMI - MentalHealth', 0.059861227400692135),\n",
       " ('BMI - DifficultyWalking', 0.20788019512527584),\n",
       " ('BMI - Gender', 0.080903183631275),\n",
       " ('BMI - Age', 0.21882047127416504),\n",
       " ('BMI - Education', -0.08831463775581311),\n",
       " ('BMI - Income', -0.1298266025074565)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e0894",
   "metadata": {},
   "source": [
    "## 3. SETUP DATA FOR CLASSIFICATION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca83dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Method to create classification Report\n",
    "def makeClassificationReport(metricsArray):\n",
    "    TN = metricsArray[0][0]\n",
    "    FN = metricsArray[0][1]\n",
    "    FP = metricsArray[1][0]\n",
    "    TP = metricsArray[1][1]\n",
    "    Accuracy = (TP+TN)/(TP+FN+TN+FP)\n",
    "    Precision = TP/(TP+FP)\n",
    "    Recall = TP / (TP + FN)\n",
    "    F1Score = 2*(Precision * Recall)/(Precision + Recall)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"Precision: \",Precision)\n",
    "    print(\"Recall: \",Recall)\n",
    "    print(\"F1- Score: \", F1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45131377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+--------------------+\n",
      "|HeartDisease|State|  BMI|HighBP|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender|Age|Education|Income|            features|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+--------------------+\n",
      "|         0.0| 22.0|23.91|   0.0|     0.0|      1.0|         1.0|             1.0|   1.0|         0.0|     0.0|   0.0|       0.0|              0.0|             1.0|          5.0|           0.0|         2.0|              0.0|   0.0|4.0|      4.0|   5.0|(20,[0,2,3,4,5,11...|\n",
      "|         1.0| 22.0|39.15|   1.0|     1.0|      1.0|         0.0|             0.0|   0.0|         0.0|     1.0|   0.0|       1.0|              1.0|             0.0|          1.0|          30.0|         0.0|              1.0|   0.0|9.0|      4.0|   5.0|(20,[0,1,2,7,9,10...|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+---+---------+------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/02 00:06:31 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numericCols = ['BMI','HighChol','CholCheck','FruitConsume','VegetableConsume','Smoker','HeavyDrinker', \\\n",
    "               'Diabetes','Stroke','Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth', \\\n",
    "               'PhysicalHealth','MentalHealth','DifficultyWalking','Gender','Age','Education','Income']\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "df = assembler.transform(heartData)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b278dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 467119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 78:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 52052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We first reserve 10% of the data to use for demonstarating the model we have developed\n",
    "# This will be completely unseen during training and selecting the model\n",
    "modelData, demoData = df.randomSplit([0.9, 0.1], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(modelData.count()))\n",
    "print(\"Test Dataset Count: \" + str(demoData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63fd4f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 326889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 84:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 140230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We now do a train test split on the modelData only\n",
    "train, test = modelData.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f5099",
   "metadata": {},
   "source": [
    "## 4. CLASSIFICATION MODEL 1 : NO OVERSAMPLING O UNDER SAMPLING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7385b",
   "metadata": {},
   "source": [
    "#### 4.1 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69253fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "|  BMI|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender| Age|Education|Income|HeartDisease|       rawPrediction|prediction|         probability|\n",
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "|16.47|     0.0|      1.0|         1.0|             1.0|   0.0|         0.0|     0.0|   0.0|       1.0|              0.0|             0.0|          2.0|          30.0|         0.0|              1.0|   0.0|11.0|      4.0|   5.0|         0.0|[16.9530676211806...|       0.0|[0.84765338105903...|\n",
      "|18.36|     0.0|      1.0|         1.0|             1.0|   0.0|         0.0|     0.0|   0.0|       1.0|              0.0|             1.0|          3.0|           4.0|         0.0|              1.0|   0.0|11.0|      5.0|   1.0|         0.0|[17.8298840010761...|       0.0|[0.89149420005380...|\n",
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'HeartDisease')\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "predictions.select('BMI','HighChol','CholCheck','FruitConsume','VegetableConsume','Smoker','HeavyDrinker', \\\n",
    "               'Diabetes','Stroke','Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth', \\\n",
    "               'PhysicalHealth','MentalHealth','DifficultyWalking','Gender','Age','Education','Income', \\\n",
    "               'HeartDisease', 'rawPrediction', 'prediction', 'probability').show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3c372",
   "metadata": {},
   "source": [
    "#### 4.2 Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff2a6073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|HeartDisease|prediction|\n",
      "+------------+----------+\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "|         0.0|       0.0|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"HeartDisease\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7afd0595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 106:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8639300477858837\n",
      "Test Error = 0.13606995221411633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 106:=======>                                                 (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6670bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127301.      0.]\n",
      " [ 12929.      0.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','HeartDisease']).withColumn('HeartDisease', F.col('HeartDisease').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','HeartDisease'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab1b60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "Accuracy:  0.9078014690151893\n",
      "Precision:  0.0\n",
      "Recall:  nan\n",
      "F1- Score:  nan\n"
     ]
    }
   ],
   "source": [
    "makeClassificationReport(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a570a",
   "metadata": {},
   "source": [
    "## 5. CLASSIFICATION MODEL WITH OVERSAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a23bff",
   "metadata": {},
   "source": [
    "#### 5.1 Code to oversample the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b22c2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col, explode, array, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9942ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 118:=======>                                                 (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "major_train = train.filter(col(\"HeartDisease\") == 0)\n",
    "minor_train = train.filter(col(\"HeartDisease\") == 1)\n",
    "\n",
    "ratio = int(major_train.count()/minor_train.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fa2a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(ratio)\n",
    "\n",
    "# duplicate the minority rows\n",
    "oversampled_train = minor_train.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5c925cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+--------------------+\n",
      "|HeartDisease|State|  BMI|HighBP|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender| Age|Education|Income|            features|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+--------------------+\n",
      "|         0.0| 22.0|16.73|   0.0|     0.0|      1.0|         1.0|             1.0|   1.0|         0.0|     1.0|   0.0|       1.0|              0.0|             1.0|          1.0|          30.0|        20.0|              0.0|   0.0| 7.0|      5.0|   3.0|[16.73,0.0,1.0,1....|\n",
      "|         0.0| 22.0|17.51|   1.0|     1.0|      1.0|         1.0|             1.0|   0.0|         0.0|     1.0|   0.0|       1.0|              0.0|             1.0|          4.0|           0.0|         0.0|              0.0|   0.0|11.0|      4.0|   8.0|(20,[0,1,2,3,4,7,...|\n",
      "+------------+-----+-----+------+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine both oversampled minority rows and previous majority rows \n",
    "combined_train = major_train.unionAll(oversampled_train)\n",
    "combined_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea423785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/02 00:06:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:06:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:06:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:06:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:06:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 128:============================>                           (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Data size 566841\n",
      "Percentage not having any heart issues\n",
      "52.377121626699555\n",
      "Percentage havingheart issues\n",
      "47.622878373300445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 128:===============================>                        (9 + 7) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Counts after oversampling the training data\n",
    "counts = combined_train.groupBy('HeartDisease').count().collect()\n",
    "total_counts = combined_train.count()\n",
    "\n",
    "\n",
    "print(\"Total Training Data size\",combined_train.count())\n",
    "print(\"Percentage not having any heart issues\" )\n",
    "print(counts[0][1]/total_counts*100)\n",
    "print(\"Percentage havingheart issues\" )\n",
    "print(counts[1][1]/total_counts*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e662cbe",
   "metadata": {},
   "source": [
    "#### 5.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd9133bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "|  BMI|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender| Age|Education|Income|HeartDisease|       rawPrediction|prediction|         probability|\n",
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "|16.47|     0.0|      1.0|         1.0|             1.0|   0.0|         0.0|     0.0|   0.0|       1.0|              0.0|             0.0|          2.0|          30.0|         0.0|              1.0|   0.0|11.0|      4.0|   5.0|         0.0|[6.37056875013597...|       1.0|[0.31852843750679...|\n",
      "|18.36|     0.0|      1.0|         1.0|             1.0|   0.0|         0.0|     0.0|   0.0|       1.0|              0.0|             1.0|          3.0|           4.0|         0.0|              1.0|   0.0|11.0|      5.0|   1.0|         0.0|[9.01121581444649...|       1.0|[0.45056079072232...|\n",
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'HeartDisease')\n",
    "rfModel = rf.fit(combined_train)\n",
    "predictions = rfModel.transform(test)\n",
    "predictions.select('BMI','HighChol','CholCheck','FruitConsume','VegetableConsume','Smoker','HeavyDrinker', \\\n",
    "               'Diabetes','Stroke','Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth', \\\n",
    "               'PhysicalHealth','MentalHealth','DifficultyWalking','Gender','Age','Education','Income', \\\n",
    "               'HeartDisease', 'rawPrediction', 'prediction', 'probability').show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077ae57",
   "metadata": {},
   "source": [
    "#### 5.3 Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b31aae57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 149:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7946650039795793\n",
      "Test Error = 0.2053349960204207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 149:=======>                                                 (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1f66741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusuion Matrix:\n",
      "[[94241. 33060.]\n",
      " [ 3015.  9914.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','HeartDisease']).withColumn('HeartDisease', F.col('HeartDisease').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','HeartDisease'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(\"Confusuion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01019c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "Accuracy:  0.7427440633245382\n",
      "Precision:  0.7668033103875009\n",
      "Recall:  0.230697631125797\n",
      "F1- Score:  0.35468579503783343\n"
     ]
    }
   ],
   "source": [
    "makeClassificationReport(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a35b90",
   "metadata": {},
   "source": [
    "## 6. CLASSIFICATION MODEL WITH UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c3665",
   "metadata": {},
   "source": [
    "#### 6.1 Code to undersample the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7d72b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col, explode, array, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "566fe858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "major_train = train.filter(col(\"HeartDisease\") == 0)\n",
    "minor_train = train.filter(col(\"HeartDisease\") == 1)\n",
    "\n",
    "ratio = int(major_train.count()/minor_train.count())\n",
    "print(\"ratio: {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d71d10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_majority_df = major_train.sample(False, 1/ratio)\n",
    "combined_train = sampled_majority_df.unionAll(minor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c9ac052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/02 00:07:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:07:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:07:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:07:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:07:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/06/02 00:07:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 170:============================>                           (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training dataset Size 63050\n",
      "Percentage not having any heart issues\n",
      "52.42823156225218\n",
      "Percentage havingheart issues\n",
      "47.57176843774782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 170:===================================================>   (15 + 1) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Counts after undersampling the training data\n",
    "counts = combined_train.groupBy('HeartDisease').count().collect()\n",
    "total_counts = combined_train.count()\n",
    "\n",
    "print(\"Total Training dataset Size\", combined_train.count())\n",
    "print(\"Percentage not having any heart issues\" )\n",
    "print(counts[0][1]/total_counts*100)\n",
    "print(\"Percentage havingheart issues\" )\n",
    "print(counts[1][1]/total_counts*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9caf2",
   "metadata": {},
   "source": [
    "#### 6.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcd6dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "|  BMI|HighChol|CholCheck|FruitConsume|VegetableConsume|Smoker|HeavyDrinker|Diabetes|Stroke|Healthcare|NoDoctorDueToCost|PhysicalActivity|GeneralHealth|PhysicalHealth|MentalHealth|DifficultyWalking|Gender| Age|Education|Income|HeartDisease|       rawPrediction|prediction|         probability|\n",
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "|16.47|     0.0|      1.0|         1.0|             1.0|   0.0|         0.0|     0.0|   0.0|       1.0|              0.0|             0.0|          2.0|          30.0|         0.0|              1.0|   0.0|11.0|      4.0|   5.0|         0.0|[6.41471164973765...|       1.0|[0.32073558248688...|\n",
      "|18.36|     0.0|      1.0|         1.0|             1.0|   0.0|         0.0|     0.0|   0.0|       1.0|              0.0|             1.0|          3.0|           4.0|         0.0|              1.0|   0.0|11.0|      5.0|   1.0|         0.0|[8.72124121115647...|       1.0|[0.43606206055782...|\n",
      "+-----+--------+---------+------------+----------------+------+------------+--------+------+----------+-----------------+----------------+-------------+--------------+------------+-----------------+------+----+---------+------+------------+--------------------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'HeartDisease')\n",
    "rfModel = rf.fit(combined_train)\n",
    "predictions = rfModel.transform(test)\n",
    "predictions.select('BMI','HighChol','CholCheck','FruitConsume','VegetableConsume','Smoker','HeavyDrinker', \\\n",
    "               'Diabetes','Stroke','Healthcare','NoDoctorDueToCost','PhysicalActivity','GeneralHealth', \\\n",
    "               'PhysicalHealth','MentalHealth','DifficultyWalking','Gender','Age','Education','Income', \\\n",
    "               'HeartDisease', 'rawPrediction', 'prediction', 'probability').show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa1d2d",
   "metadata": {},
   "source": [
    "#### 6.3 Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d616d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.786706714861117\n",
      "Test Error = 0.21329328513888302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 191:===================================>                     (5 + 3) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7cb4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 193:>                                                        (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusuion Matrix:\n",
      "[[92461. 34840.]\n",
      " [ 2771. 10158.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','HeartDisease']).withColumn('HeartDisease', F.col('HeartDisease').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','HeartDisease'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(\"Confusuion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "388e3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "Accuracy:  0.7317906296798118\n",
      "Precision:  0.7856756129631062\n",
      "Recall:  0.22574336637183876\n",
      "F1- Score:  0.3507172820964317\n"
     ]
    }
   ],
   "source": [
    "makeClassificationReport(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c925d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model to specified path\n",
    "# Comment after running once\n",
    "# mPath =  \"../model/\"\n",
    "#rfModel.write().overwrite().save(mPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740696e",
   "metadata": {},
   "source": [
    "### Note: We are choosing the Model with Undersampled since it has slightly better metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5618b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
